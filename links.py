import os
import sys
import csv
import json
import time
from playwright.sync_api import sync_playwright
import tkinter as tk
from tkinter import ttk

# ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø§ÙØ°Ø© `tkinter` Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
root = tk.Tk()
root.title("\U0001F501 Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°...")
root.geometry("300x150")
root.resizable(False, False)
status_label = ttk.Label(root, text="\U0001F501 Ø¬Ø§Ø±ÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ©...", font=("Arial", 12))
status_label.pack(pady=30)
root.update()

# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ´ØºÙŠÙ„
app_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
users_path = os.path.join(app_dir, "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….txt")
words_path = os.path.join(app_dir, "ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«.txt")
output_path = os.path.join(app_dir, "Ø§Ù„Ù†ØªØ§Ø¦Ø¬.csv")
cookies_path = os.path.join(app_dir, "cookies.json")
chromium_path = os.path.join(app_dir, "chromium", "chrome.exe")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
with open(words_path, "r", encoding="utf-8") as f:
    target_words = [w.strip().lower() for w in f if w.strip()]
print("\U0001F4CC ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«:", target_words)

# ØªØ¬Ù‡ÙŠØ² Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
with open(output_path, mode="w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Username", "Source", "Matched Words"])

with sync_playwright() as p:
    browser = p.chromium.launch(executable_path=chromium_path, headless=False)
    context = browser.new_context()

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
    with open(cookies_path, "r", encoding="utf-8") as f:
        cookies = json.load(f)
        context.add_cookies(cookies)

    page = context.new_page()
    page.goto("https://x.com/home")
    time.sleep(4)

    with open(users_path, "r", encoding="utf-8") as file:
        for username in file:
            username = username.strip()
            if not username.startswith("http"):
                continue

            print(f"\n\U0001F539 ÙØªØ­ Ø§Ù„Ø­Ø³Ø§Ø¨: {username}")
            status_label_text = None

            try:
                page.goto(username, timeout=10000)
                time.sleep(4)

                # âœ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªØ­Ø°ÙŠØ± Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø³Ø§Ø³
                try:
                    sensitive_text_xpath = 'xpath=//*[@id="react-root"]/div/div/div[2]/main/div/div/div/div/div/div/div/div/div[2]/div/div[2]'
                    confirm_button_xpath = 'xpath=//*[@id="react-root"]/div/div/div[2]/main/div/div/div/div/div/div/div/div/div[2]/div/button'

                    sensitive_element = page.query_selector(sensitive_text_xpath)
                    if sensitive_element:
                        text_content = sensitive_element.inner_text().strip()
                        if "Ø§Ù†Øª ØªØ´Ø§Ù‡Ø¯" in text_content or "ØªØ­Ø°ÙŠØ±" in text_content or "Ø£Ù†Øª ØªØ´Ø§Ù‡Ø¯" in text_content or "Caution" in text_content or "Youâ€™re seeing" in text_content or "You are seeing" in text_content:
                            print("\u26a0\ufe0f Ø§Ù„Ø­Ø³Ø§Ø¨ ÙŠØ­ØªÙˆÙŠ ØªØ­Ø°ÙŠØ± Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø§Ø³ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø±...")
                            confirm_button = page.query_selector(confirm_button_xpath)
                            if confirm_button:
                                confirm_button.click()
                                time.sleep(2)
                            status_label_text = "sensitive"
                except Exception as e:
                    print(f"\U0001F538 ØªØ¹Ø°Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ­Ø°ÙŠØ± Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø³Ø§Ø³: {e}")

                # âœ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…ÙˆÙ‚ÙˆÙØ©
                try:
                    suspended_account_xpath = 'xpath=//*[@id="react-root"]/div/div/div[2]/main/div/div/div/div/div/div/div/div/div[2]/div/div[1]/span'
                    suspended_element = page.query_selector(suspended_account_xpath)
                    if suspended_element:
                        suspended_text = suspended_element.inner_text().strip()
                        if "Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚ÙˆÙ" in suspended_text or "Account suspended" in suspended_text:
                            print("\U0001f6ab Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹Ù„Ù‚ØŒ Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸Ù‡...")
                            with open(output_path, mode="a", newline="", encoding="utf-8") as f:
                                writer = csv.writer(f)
                                writer.writerow([username, "suspended", "suspended"])
                            continue
                except Exception as e:
                    print(f"\u274c Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨: {e}")

                # ğŸ” BIO
                match_found = None
                bio_element = page.query_selector('div[data-testid="UserDescription"]')
                if bio_element:
                    bio_text = bio_element.inner_text().strip().lower()
                    bio_matches = [w for w in target_words if w in bio_text]
                    if bio_matches:
                        match_found = ("bio", ", ".join(bio_matches))
                time.sleep(0.5)

                # âœ… user_url
                if not match_found:
                    url_element = page.query_selector('xpath=//*[@id="react-root"]/div/div/div[2]/main/div/div/div/div/div/div/div/div/div[2]/div/div[1]/span')
                    if url_element:
                        url_text = url_element.inner_text().strip().lower()
                        url_matches = [w for w in target_words if w in url_text]
                        if url_matches:
                            match_found = ("user_url", ", ".join(url_matches))
                time.sleep(0.5)

                # âœ… tweets
                if not match_found:
                    tweet_elements = page.locator('div[data-testid="tweetText"]').all()[:10]
                    for tweet in tweet_elements:
                        tweet_text = tweet.inner_text().strip().lower()
                        tweet_matches = [w for w in target_words if w in tweet_text]
                        if tweet_matches:
                            match_found = ("tweet", ", ".join(tweet_matches))
                            break
                time.sleep(0.5)

                # âœï¸ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                if match_found:
                    with open(output_path, mode="a", newline="", encoding="utf-8") as f:
                        writer = csv.writer(f)
                        writer.writerow([username, match_found[0], match_found[1]])
                    print(f"\u2705 ØªØ·Ø§Ø¨Ù‚ ÙÙŠ {match_found[0]} Ù„Ù€ {username} â†’ {match_found[1]}")

                elif status_label_text == "sensitive":
                    with open(output_path, mode="a", newline="", encoding="utf-8") as f:
                        writer = csv.writer(f)
                        writer.writerow([username, "sensitive", "sensitive"])
                    print(f"\u26a0\ufe0f Ø§Ù„Ø­Ø³Ø§Ø¨ Ø­Ø³Ø§Ø³ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„Ù‡ ÙƒÙ€ sensitive")

                else:
                    with open(output_path, mode="a", newline="", encoding="utf-8") as f:
                        writer = csv.writer(f)
                        writer.writerow([username, "no_match", "no_match"])
                    print(f"\u274c Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ·Ø§Ø¨Ù‚ ÙÙŠ {username}")

            except Exception as e:
                print(f"\u274c Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ÙØªØ­ Ø§Ù„Ø­Ø³Ø§Ø¨   {username}: {e}")

    browser.close()
    root.after(3000, root.destroy)
    root.mainloop()
    sys.exit(0)